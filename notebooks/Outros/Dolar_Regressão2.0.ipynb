{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmcXlaUYeM5n"
      },
      "source": [
        "# Configurações Iniciais"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqWYYW2WeFpf",
        "outputId": "794aa5af-d84a-4249-c5b9-5db5e8dd9b6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: xgboost in d:\\programas\\anaconda\\lib\\site-packages (1.7.6)\n",
            "Requirement already satisfied: numpy in d:\\programas\\anaconda\\lib\\site-packages (from xgboost) (1.24.3)\n",
            "Requirement already satisfied: scipy in d:\\programas\\anaconda\\lib\\site-packages (from xgboost) (1.10.1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_20780\\135771212.py:33: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
            "  df_2020 = pd.read_csv(r\"C:\\Users\\PC\\Desktop\\BASES MOBLY-20230731T191159Z-001 (1)\\BASES MOBLY\\base_inteli 2020_2021.csv\", ';')\n",
            "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_20780\\135771212.py:34: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument 'filepath_or_buffer' will be keyword-only.\n",
            "  df_2022 = pd.read_csv(r\"C:\\Users\\PC\\Desktop\\BASES MOBLY-20230731T191159Z-001 (1)\\BASES MOBLY\\base_inteli_2022_2023.csv\", ';')\n"
          ]
        }
      ],
      "source": [
        "# Importando bibliotecas\n",
        "!pip install xgboost\n",
        "import numpy as np\n",
        "from numpy import mean, std\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import tkinter\n",
        "import plotly.express as px\n",
        "from collections import Counter\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.lines import Line2D\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.metrics import *\n",
        "from sklearn.feature_selection import RFECV\n",
        "import xgboost as xgb\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import RepeatedKFold\n",
        "from prophet import Prophet\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "\n",
        "# pd.set_option('display.max_rows', None)\n",
        "# Retirar os limitadores de coluna\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "# Unindo as bases de dados e removendo as não utilizadas\n",
        "\n",
        "df_2020 = pd.read_csv(r\"C:\\Users\\PC\\Desktop\\BASES MOBLY-20230731T191159Z-001 (1)\\BASES MOBLY\\base_inteli 2020_2021.csv\", ';')\n",
        "df_2022 = pd.read_csv(r\"C:\\Users\\PC\\Desktop\\BASES MOBLY-20230731T191159Z-001 (1)\\BASES MOBLY\\base_inteli_2022_2023.csv\", ';')\n",
        "df_dolar_2020 = pd.read_csv(r\"C:\\Users\\PC\\Downloads\\USDBRL(2020).csv\")\n",
        "df_dolar_2021 = pd.read_csv(r\"C:\\Users\\PC\\Downloads\\USDBRL(2021).csv\")\n",
        "df_dolar_2022 = pd.read_csv(r\"C:\\Users\\PC\\Downloads\\USDBRL(2022).csv\")\n",
        "df_dolar_2023 = pd.read_csv(r\"C:\\Users\\PC\\Downloads\\USDBRL(2023).csv\")\n",
        "df_all = pd.concat([df_2020, df_2022])\n",
        "df_dolar = pd.concat([df_dolar_2020, df_dolar_2021, df_dolar_2022, df_dolar_2023])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "***Adicionando cotação do dolar no dataframe***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_dolar.rename(columns={\"Date\": \"date\"}, inplace=True)\n",
        "df_dolar.rename(columns={\"Close\": \"dollar_quotation\"}, inplace=True)\n",
        "df_dolar = df_dolar.drop(['Open', 'High', 'Low', 'Adj Close', 'Volume'], axis=1)\n",
        "df_dolar['dollar_quotation'] = df_dolar['dollar_quotation'].apply(lambda x: round(x, 4))\n",
        "df_all = pd.merge(df_all, df_dolar, how='left')\n",
        "df_all['dollar_quotation'].fillna(method='ffill', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>dollar_quotation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-01-01</td>\n",
              "      <td>4.0168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-01-02</td>\n",
              "      <td>4.0163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-01-03</td>\n",
              "      <td>4.0234</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-01-06</td>\n",
              "      <td>4.0570</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-01-07</td>\n",
              "      <td>4.0604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2020-01-08</td>\n",
              "      <td>4.0662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2020-01-09</td>\n",
              "      <td>4.0628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2020-01-10</td>\n",
              "      <td>4.0921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2020-01-13</td>\n",
              "      <td>4.0705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2020-01-14</td>\n",
              "      <td>4.1458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>2020-01-15</td>\n",
              "      <td>4.1313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>2020-01-16</td>\n",
              "      <td>4.1742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>2020-01-17</td>\n",
              "      <td>4.1836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>2020-01-20</td>\n",
              "      <td>4.1616</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>2020-01-21</td>\n",
              "      <td>4.1885</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>2020-01-22</td>\n",
              "      <td>4.2109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>2020-01-23</td>\n",
              "      <td>4.1813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>2020-01-24</td>\n",
              "      <td>4.1691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2020-01-27</td>\n",
              "      <td>4.1595</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2020-01-28</td>\n",
              "      <td>4.2061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>2020-01-29</td>\n",
              "      <td>4.1934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>2020-01-30</td>\n",
              "      <td>4.2289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>2020-01-31</td>\n",
              "      <td>4.2422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>2020-02-03</td>\n",
              "      <td>4.2826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2020-02-04</td>\n",
              "      <td>4.2468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>2020-02-05</td>\n",
              "      <td>4.2537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>2020-02-06</td>\n",
              "      <td>4.2336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>2020-02-07</td>\n",
              "      <td>4.2808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2020-02-10</td>\n",
              "      <td>4.3204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>2020-02-11</td>\n",
              "      <td>4.3210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>2020-02-12</td>\n",
              "      <td>4.3275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>2020-02-13</td>\n",
              "      <td>4.3545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>2020-02-14</td>\n",
              "      <td>4.3468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>2020-02-17</td>\n",
              "      <td>4.2970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>2020-02-18</td>\n",
              "      <td>4.3265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>2020-02-19</td>\n",
              "      <td>4.3548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>2020-02-20</td>\n",
              "      <td>4.3640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>2020-02-21</td>\n",
              "      <td>4.3923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>2020-02-24</td>\n",
              "      <td>4.3898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>2020-02-25</td>\n",
              "      <td>4.3866</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>2020-02-26</td>\n",
              "      <td>4.3868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>2020-02-27</td>\n",
              "      <td>4.4491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>2020-02-28</td>\n",
              "      <td>4.4848</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>2020-03-02</td>\n",
              "      <td>4.4413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>2020-03-03</td>\n",
              "      <td>4.4724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>2020-03-04</td>\n",
              "      <td>4.5132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>2020-03-05</td>\n",
              "      <td>4.5834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>2020-03-06</td>\n",
              "      <td>4.6062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>2020-03-09</td>\n",
              "      <td>4.5898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>2020-03-10</td>\n",
              "      <td>4.7229</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          date  dollar_quotation\n",
              "0   2020-01-01            4.0168\n",
              "1   2020-01-02            4.0163\n",
              "2   2020-01-03            4.0234\n",
              "3   2020-01-06            4.0570\n",
              "4   2020-01-07            4.0604\n",
              "5   2020-01-08            4.0662\n",
              "6   2020-01-09            4.0628\n",
              "7   2020-01-10            4.0921\n",
              "8   2020-01-13            4.0705\n",
              "9   2020-01-14            4.1458\n",
              "10  2020-01-15            4.1313\n",
              "11  2020-01-16            4.1742\n",
              "12  2020-01-17            4.1836\n",
              "13  2020-01-20            4.1616\n",
              "14  2020-01-21            4.1885\n",
              "15  2020-01-22            4.2109\n",
              "16  2020-01-23            4.1813\n",
              "17  2020-01-24            4.1691\n",
              "18  2020-01-27            4.1595\n",
              "19  2020-01-28            4.2061\n",
              "20  2020-01-29            4.1934\n",
              "21  2020-01-30            4.2289\n",
              "22  2020-01-31            4.2422\n",
              "23  2020-02-03            4.2826\n",
              "24  2020-02-04            4.2468\n",
              "25  2020-02-05            4.2537\n",
              "26  2020-02-06            4.2336\n",
              "27  2020-02-07            4.2808\n",
              "28  2020-02-10            4.3204\n",
              "29  2020-02-11            4.3210\n",
              "30  2020-02-12            4.3275\n",
              "31  2020-02-13            4.3545\n",
              "32  2020-02-14            4.3468\n",
              "33  2020-02-17            4.2970\n",
              "34  2020-02-18            4.3265\n",
              "35  2020-02-19            4.3548\n",
              "36  2020-02-20            4.3640\n",
              "37  2020-02-21            4.3923\n",
              "38  2020-02-24            4.3898\n",
              "39  2020-02-25            4.3866\n",
              "40  2020-02-26            4.3868\n",
              "41  2020-02-27            4.4491\n",
              "42  2020-02-28            4.4848\n",
              "43  2020-03-02            4.4413\n",
              "44  2020-03-03            4.4724\n",
              "45  2020-03-04            4.5132\n",
              "46  2020-03-05            4.5834\n",
              "47  2020-03-06            4.6062\n",
              "48  2020-03-09            4.5898\n",
              "49  2020-03-10            4.7229"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_dolar.head(50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "date\n",
              "2020-01-05    4.018833\n",
              "2020-01-12    4.067700\n",
              "2020-01-19    4.141080\n",
              "2020-01-26    4.182280\n",
              "2020-02-02    4.206020\n",
              "2020-02-09    4.259500\n",
              "2020-02-16    4.334040\n",
              "2020-02-23    4.346920\n",
              "2020-03-01    4.419420\n",
              "2020-03-08    4.523300\n",
              "2020-03-15    4.711760\n",
              "2020-03-22    5.011900\n",
              "2020-03-29    5.068320\n",
              "2020-04-05    5.200860\n",
              "2020-04-12    5.216960\n",
              "2020-04-19    5.186780\n",
              "2020-04-26    5.370620\n",
              "2020-05-03    5.508680\n",
              "2020-05-10    5.627920\n",
              "2020-05-17    5.774940\n",
              "2020-05-24    5.714460\n",
              "2020-05-31    5.398480\n",
              "2020-06-07    5.215880\n",
              "2020-06-14    4.925340\n",
              "2020-06-21    5.209940\n",
              "2020-06-28    5.283800\n",
              "2020-07-05    5.403960\n",
              "2020-07-12    5.344780\n",
              "2020-07-19    5.358560\n",
              "2020-07-26    5.242300\n",
              "2020-08-02    5.169100\n",
              "2020-08-09    5.290460\n",
              "2020-08-16    5.420020\n",
              "2020-08-23    5.501360\n",
              "2020-08-30    5.582500\n",
              "2020-09-06    5.381360\n",
              "2020-09-13    5.317780\n",
              "2020-09-20    5.266520\n",
              "2020-09-27    5.474620\n",
              "2020-10-04    5.620440\n",
              "2020-10-11    5.611740\n",
              "2020-10-18    5.565780\n",
              "2020-10-25    5.610740\n",
              "2020-11-01    5.693360\n",
              "2020-11-08    5.684760\n",
              "2020-11-15    5.401600\n",
              "2020-11-22    5.373060\n",
              "2020-11-29    5.369840\n",
              "2020-12-06    5.249160\n",
              "2020-12-13    5.113260\n",
              "Freq: W-SUN, Name: dollar_quotation, dtype: float64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Convert the 'Date' column to datetime\n",
        "df_dolar['date'] = pd.to_datetime(df_dolar['date'])\n",
        "\n",
        "# Set 'Date' as the index\n",
        "df_dolar.set_index('date', inplace=True)\n",
        "\n",
        "# Resample to weekly frequency and calculate the mean\n",
        "df_dolar_semanal = df_dolar['dollar_quotation'].resample('W').mean()\n",
        "df_dolar_semanal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_all = pd.merge(df_all, df_dolar_semanal, how='left')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpYAyEOcQl37"
      },
      "source": [
        "# Exploração dos dados\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch16dkCeF_RS"
      },
      "source": [
        "###Identificação das colunas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0-dY1WbQfem"
      },
      "source": [
        "A identificação das colunas desempenha um papel importante no processo de exploração. Através dela, podemos conhecer mais sobre os tipos de dados presente em cada coluna e direcionar o tratamento adequado que iremos utilizar para cada caso."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuhpN7JYH3X0",
        "outputId": "49c010fd-76de-425d-d386-b1e995c53a9a"
      },
      "outputs": [],
      "source": [
        "df_all.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScVIUTrxKeIn"
      },
      "source": [
        "Através do método `info()`, foi possível classificar nossas características em numéricas ou categóricas:\n",
        "\n",
        "**Colunas numéricas**\n",
        "\n",
        "---\n",
        "\n",
        "* unit_price\n",
        "* sku_height\n",
        "* sku_width\n",
        "* sku_length\n",
        "* sku_weight\n",
        "* winning_price\n",
        "* revenue\n",
        "* items_sold\n",
        "* avg_website_visits_last_week\n",
        "* supplier_delivery_time\n",
        "* stock_qty\n",
        "* revenue_bundle\n",
        "* items_sold_bundle\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "**Colunas categóricas**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "* date\n",
        "* weekday_name\n",
        "* sku\n",
        "* mobly_item\n",
        "* shipment_type\n",
        "* anchor_category\n",
        "* product_department\n",
        "* product_category\n",
        "* origin_country\n",
        "* process_costing\n",
        "* sku_color\n",
        "* price_status\n",
        "* flag_bundle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UudWrDkaEGO9"
      },
      "source": [
        "###Estatística descritiva das colunas\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6w7z5mK6PEya"
      },
      "source": [
        "A estatística descritiva é uma parte da estatística que envolve a coleta, organização, resumo e interpretação de dados para descrever características importantes de um conjunto de informações. Ela se concentra em transformar dados brutos em informações compreensíveis e significativas, permitindo uma compreensão mais clara das tendências, padrões e distribuições presentes nos dados.\n",
        "\n",
        "Para o caso do nosso projeto, a estatística descritiva desempenha um papel importante para a ideação de um modelo preditivo de regressão. Antes de construir esse modelo, é fundamental entender a distribuição dos dados históricos de vendas. Então, a estatística descritiva, como a média, mediana, desvio padrão e percentis, ajuda a identificar não apenas as tendências, mas também os outliers nos dados de vendas passados.\n",
        "\n",
        "O método nativo `describe()` da biblioteca Pandas foi utilizado para fazer a análise exploratória dos dados, já que fornece estatísticas para cada uma das colunas do dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZQCR3TTEmDm",
        "outputId": "bea8419c-b80b-4fc5-8844-93f05550a0bd"
      },
      "outputs": [],
      "source": [
        "df_all.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNbmndZFEsEU"
      },
      "source": [
        "Com o banco de dados original apresentando algumas informações faltantes em certas linhas, as estatísticas descritivas puderam ser utilizadas para imputar os dados ausentes. Isso pôde ser feito por meio da utilização da mediana, por exemplo, atribuindo o valor dessa tendência central nos campos em branco."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmIM8T3VQory"
      },
      "source": [
        "# Pré-processamento\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxj597BzOA1"
      },
      "source": [
        "###Limpeza de dados\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAR6juIwzbdL"
      },
      "source": [
        "**Tratamento de missings e remoção das colunas**\n",
        "\n",
        "---\n",
        "Removemos as colunas que possuíam somente um valor exclusivo, aquelas que apresentavam mais de 50% dos seus valores vazios ou sem registro e as que continham valores irrelevantes para o nosso modelo.\n",
        "\n",
        "As colunas possuíam poucos missing values, apenas presentes em algumas dimensões de sku’s, então optamos por substituir esses valores por 0, visto que a inexistência de informações sobre suas dimensões não alterava em sua venda."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHKu8aps9Aor",
        "outputId": "11aac485-0a48-489d-dd98-952002192795"
      },
      "outputs": [],
      "source": [
        "# Função para encontrar o índice da primeira venda ou visita\n",
        "def find_first_occurrence(df_all):\n",
        "    condition = (df_all['items_sold'] > 0) | (df_all['avg_website_visits_last_week'] > 0)\n",
        "    if condition.any():\n",
        "        return condition.idxmax()\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Aplica a função para cada grupo de Produto e cria a máscara\n",
        "mask = df_all.groupby('sku').apply(find_first_occurrence).reset_index(name='first_occurrence_index')\n",
        "df_all = df_all.merge(mask, on='sku', how='left')\n",
        "keep_rows = df_all.index >= df_all['first_occurrence_index']\n",
        "\n",
        "# Filtrar o dataframe usando a máscara\n",
        "df_all = df_all[keep_rows].drop(columns=['first_occurrence_index'])\n",
        "\n",
        "display(df_all.sort_values('date'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "id": "n5jelZeBzWCm",
        "outputId": "c78c4507-7450-4ade-feec-4a93a89f2999"
      },
      "outputs": [],
      "source": [
        "df_fixed = df_all.drop([\"mobly_item\",'price_status','winning_price', 'revenue','revenue_bundle'], axis ='columns').fillna(0).reset_index(drop = True)\n",
        "display(df_fixed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZL65fDt9Aos"
      },
      "outputs": [],
      "source": [
        "df_fixed = df_fixed[df_fixed['items_sold'] != -1].reset_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uu7obFGRehZ3"
      },
      "source": [
        "### Adequação de variáveis numéricas e categóricas\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEdFdvPV4ab4"
      },
      "source": [
        "**Separação das variáveis**\n",
        "\n",
        "---\n",
        "*(Revisar e corrigir)*<BR>\n",
        "Todas as colunas identificadas como categóricas em nossa database foram percorridas, contando o número de valores únicos presentes. Com base nessa contagem, foi possível compreender a variedade de categorias por atributo, separando as colunas pelo método que seriam codificadas: One-Hot Encoder ou Label Encoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UM3zvVmXehB8",
        "outputId": "63c7924e-b420-4f5b-c4bd-cfb4f1a69588"
      },
      "outputs": [],
      "source": [
        "columns = list(df_fixed.columns)\n",
        "\n",
        "categoric_columns = []\n",
        "numeric_columns = []\n",
        "\n",
        "for i in columns:\n",
        "    if len(df_fixed[i].unique()) > 7:\n",
        "        numeric_columns.append(i)\n",
        "    else:\n",
        "        categoric_columns.append(i)\n",
        "\n",
        "\n",
        "\n",
        "print('Label Encoding: ',numeric_columns)\n",
        "print('One-Hot Encoding: ',categoric_columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eJoxDWnmKV0"
      },
      "source": [
        "**One-Hot Encoder**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Empregamos o One-Hot Encoder em colunas categóricas com até 7 elementos. Essa escolha foi feita para converter essas colunas em um formato binário sem sobrecarregar o sistema. O processo desse codificador gera uma coluna nova para representar cada categoria, na qual o valor é atribuído como \"1\" ou \"0\" para indicar se está presente ou ausente, respectivamente.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 704
        },
        "id": "yrZqaq9IvFHk",
        "outputId": "d249ab1d-8ab4-424b-83d7-9b239a2e6c3e"
      },
      "outputs": [],
      "source": [
        "# Selecionando as colunas para sofrerem codificação\n",
        "columns_to_encode = ['shipment_type', 'product_department', 'origin_country', 'process_costing', 'flag_bundle']\n",
        "data_to_encode = df_fixed[columns_to_encode]\n",
        "\n",
        "# Transformando as colunas para um novo DataFrame\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "encoded = encoder.fit_transform(data_to_encode)\n",
        "df_oneHot = pd.DataFrame(encoded, columns=encoder.get_feature_names_out(columns_to_encode))\n",
        "\n",
        "# Substituir as colunas originais pelas colunas do df_oneHot\n",
        "df_fixed_encoded = df_fixed.drop(columns=columns_to_encode)  # Remover as colunas originais\n",
        "df_fixed_encoded = pd.concat([df_fixed_encoded, df_oneHot], axis=1)  # Concatenar as colunas codificadas\n",
        "\n",
        "display(df_fixed_encoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nw66FRNMvQUG"
      },
      "source": [
        "**Label Encoder**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "Utilizamos o Label Encoder em colunas categóricas com 7 ou mais elementos. Nesse processo, cada item da categoria era atribuído a um número inteiro distinto, não expandindo o número de colunas.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "m5hEpz6CwUzi",
        "outputId": "fec060d3-06c9-470d-b185-a1d6dbcac77b"
      },
      "outputs": [],
      "source": [
        "# Agrupa os items vendidos de acordo com cada item de uma coluna\n",
        "color_sums = df_fixed_encoded.groupby(['sku_color'])['items_sold'].sum().sort_values(ascending=True)\n",
        "sku_sums = df_fixed_encoded.groupby(['sku'])['items_sold'].sum().sort_values(ascending=True)\n",
        "anchor_sums = df_fixed_encoded.groupby(['anchor_category'])['items_sold'].sum().sort_values(ascending=True)\n",
        "product_sums = df_fixed_encoded.groupby(['product_category'])['items_sold'].sum().sort_values(ascending=True)\n",
        "\n",
        "# Cria um dicionário mapeando as cores de forma ordinal (Maior para menor)\n",
        "color_ordinal_mapping = {color: i for i, color in enumerate(color_sums.index)}\n",
        "sku_ordinal_mapping = {sku: i for i, sku in enumerate(sku_sums.index)}\n",
        "anchor_ordinal_mapping = {anchor: i for i, anchor in enumerate(anchor_sums.index)}\n",
        "product_ordinal_mapping = {product: i for i, product in enumerate(product_sums.index)}\n",
        "\n",
        "# Aplica Ordinal encoding\n",
        "encoder_color = OrdinalEncoder(categories=[list(color_ordinal_mapping.keys())])\n",
        "encoder_sku = OrdinalEncoder(categories=[list(sku_ordinal_mapping.keys())])\n",
        "encoder_anchor = OrdinalEncoder(categories=[list(anchor_ordinal_mapping.keys())])\n",
        "encoder_product = OrdinalEncoder(categories=[list(product_ordinal_mapping.keys())])\n",
        "\n",
        "# Cria as novas colunas\n",
        "df_fixed_encoded['color_encoded'] = encoder_color.fit_transform(df_fixed_encoded[['sku_color']])\n",
        "df_fixed_encoded['sku_encoded'] = encoder_sku.fit_transform(df_fixed_encoded[['sku']])\n",
        "df_fixed_encoded['anchor_category_encoded'] = encoder_anchor.fit_transform(df_fixed_encoded[['anchor_category']])\n",
        "df_fixed_encoded['product_category_encoded'] = encoder_product.fit_transform(df_fixed_encoded[['product_category']])\n",
        "\n",
        "df_encoded = df_fixed_encoded.drop(['sku','anchor_category','product_category','sku_color'], axis = 1)\n",
        "df_test = df_fixed_encoded.drop(['sku','anchor_category','product_category','sku_color'], axis = 1)\n",
        "display(df_encoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N28xZNu3wfw4"
      },
      "source": [
        "**Tratamento de datas**\n",
        "\n",
        "\n",
        "---\n",
        "A coluna \"date\" possui uma alta relevância para nosso modelo, porém necessitava ser modificada para se adaptar melhor ao funcionamento dele.\n",
        "\n",
        "Transformamos seu formato de Ano / Mês / Dia para uma divisão em diversas colunas representando. Assim, o modelo consegue ler melhor os dados de data uma vez que eles foram passados de String > DateTime > Números, facilitando o entendimento da máquina e do modelo.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "NXhIKtvSxTTv",
        "outputId": "5ec1234f-220a-4284-d674-11f0b3b8f9f0"
      },
      "outputs": [],
      "source": [
        "# Transformar os valores de \"String\" de data em \"DateTime\"\n",
        "df_test['date'] = pd.to_datetime(df_encoded['date'], format='%Y-%m-%d')\n",
        "df_encoded['date'] = pd.to_datetime(df_encoded['date'], format='%Y-%m-%d')\n",
        "\n",
        "# Extraindo os componentes da date\n",
        "df_encoded['ano'] = df_encoded['date'].dt.year\n",
        "df_encoded['mes'] = df_encoded['date'].dt.month\n",
        "df_encoded['dia'] = df_encoded['date'].dt.day\n",
        "df_encoded['dia_da_semana'] = df_encoded['date'].dt.weekday  # 0: Segunda-feira, 1: Terça-feira, etc.\n",
        "df_encoded['semana_do_ano'] = df_encoded['date'].dt.isocalendar().week\n",
        "df_encoded['trimestre'] = df_encoded['date'].dt.quarter\n",
        "df_encoded['dia_do_ano'] = df_encoded['date'].dt.dayofyear\n",
        "df_encoded['eh_fim_de_semana'] = df_encoded['date'].dt.weekday >= 5  # Retorna True para sábado e domingo\n",
        "\n",
        "# Remoção das colunas antigas\n",
        "df_dates_fixed = df_encoded.drop(['date','weekday_name'], axis = 1)\n",
        "df_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60s0194C1az2"
      },
      "source": [
        "**Normalização de colunas e outliers**\n",
        "\n",
        "\n",
        "---\n",
        "Os dados numéricos foram analisados para verificar a necessidade de tratamento de outliers, valores muito grandes ou destoantes em relação aos outros no dataframe.\n",
        "\n",
        "Foi realizada uma normalização onde esses valores foram transformados em valores entre -1 e 1, mantendo sua grandeza entre si, mas não influenciando por seu tamanho e sim mais por sua força de correlação com os demais atributos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 495
        },
        "id": "ZyGjx57a1ajJ",
        "outputId": "97a8b8f6-c200-4175-f0fa-280fdcfa98ca"
      },
      "outputs": [],
      "source": [
        "# Seleção de características para serem normalizadas\n",
        "df_scale = df_test[['avg_website_visits_last_week','sku_height','sku_width','sku_length','sku_weight','unit_price','supplier_delivery_time']]\n",
        "df_toScale = df_dates_fixed[['avg_website_visits_last_week','sku_height','sku_width','sku_length','sku_weight','unit_price','supplier_delivery_time']]\n",
        "\n",
        "# Criando o objeto StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Ajustando e transformando os dados\n",
        "df_scaled = pd.DataFrame(scaler.fit_transform(df_toScale), columns=df_toScale.columns)\n",
        "df_jaaj =  pd.DataFrame(scaler.fit_transform(df_scale), columns=df_scale.columns)\n",
        "# Removendo as colunas antigas e unindo as novas\n",
        "replace = df_dates_fixed.drop(['avg_website_visits_last_week','sku_height','sku_width','sku_length','sku_weight','unit_price','supplier_delivery_time'], axis = 1)\n",
        "reprace = df_test.drop(['avg_website_visits_last_week','sku_height','sku_width','sku_length','sku_weight','unit_price','supplier_delivery_time'], axis = 1)\n",
        "df_final = replace.join(df_scaled, rsuffix='_right')\n",
        "df_ending = replace.join(df_jaaj, rsuffix='_right')\n",
        "display(df_ending)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sTOXuuc9Aou",
        "outputId": "fac3be2d-fdf9-4b24-c805-115762b03b5c"
      },
      "outputs": [],
      "source": [
        "df_final = df_final.drop(df_final[(df_final['semana_do_ano'] >= 46) & (df_final['semana_do_ano'] <= 51)].index)\n",
        "df_final = df_final.reset_index(drop = True)\n",
        "df_final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dY8qojLmQ1M3"
      },
      "source": [
        "# Hipóteses\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sTVoKmJXtOO"
      },
      "source": [
        "As hipóteses são possíveis explicações das tendências comportamentamentais dos dados, ajudando a compreensão deste e guiando enfim a acurácia mais precisa do modelo preditivo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZDRwxzpmBsC"
      },
      "source": [
        "###Hipótese #1\n",
        "\n",
        "Como explicado pelos internos da Mobly, o \"crossdocking\" é um sistema em que os itens são entregues diretamente do fornecedor para os centros de distribuição encaminharem para os clientes, sem passar pelo estoque. Esse método é utilizado quando não há o produto no estoque. Fizemos uma análise das colunas de 'shipment_type', 'sotck_qty' e 'items_sold', notando que algumas informações se destoam das que foram informadas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuqF-TmgUQCF"
      },
      "source": [
        "É possível visualizar no gráfico abaixo que a maior parte das vendas ocorreram em produtos que já estavam em estoque.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "id": "L_W2D_5HW_ZM",
        "outputId": "9a2e5c1f-d6a9-4adc-84ff-c43956ac1240"
      },
      "outputs": [],
      "source": [
        "# Classificando os produtos\n",
        "produtos_vazios_vendidos = df_final[df_final['stock_qty'] <= 0]\n",
        "produtos_com_estoque_vendidos = df_final[df_final['stock_qty'] > 0]\n",
        "\n",
        "#Contando o número de produtos em cada categoria\n",
        "num_produtos_vazios_vendidos = len(produtos_vazios_vendidos)\n",
        "num_produtos_com_estoque_vendidos = len(produtos_com_estoque_vendidos)\n",
        "\n",
        "# Criando o gráfico de pizza\n",
        "labels = ['Produtos Sem Estoque Vendidos', 'Produtos com Estoque Vendidos']\n",
        "sizes = [num_produtos_vazios_vendidos, num_produtos_com_estoque_vendidos]\n",
        "colors = ['#ff9999', '#66b2ff']\n",
        "explode = (0.1, 0)  # Explode 1st slice\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=140)\n",
        "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoBTVvM5YSiY"
      },
      "source": [
        "No entanto, neste segundo gráfico, obtemos a informação de que mais de 70% das vendas foram realizadas por crossdocking.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "UXthf88_YkJV",
        "outputId": "ea4e2d87-2311-4b36-b1a7-e6c907d0ceae"
      },
      "outputs": [],
      "source": [
        "crossdocking_and_in_stock = df_final.loc[(df_final['shipment_type_crossdocking'] == 1.0) & (df_final['stock_qty'] > 0)]\n",
        "\n",
        "# Contando a quantidade de SKUs únicos que fazem crossdocking e estão no estoque\n",
        "unique_skus_crossdocking_and_in_stock = crossdocking_and_in_stock['sku_encoded'].nunique()\n",
        "\n",
        "# Contando a quantidade total de SKUs únicos\n",
        "total_unique_skus = df_final['sku_encoded'].nunique()\n",
        "labels = [' Com Crossdocking e em Estoque', 'Sem Crossdocking e em Estoque']\n",
        "# Calculando a quantidade de SKUs que não fazem crossdocking e estão no estoque\n",
        "unique_skus_not_crossdocking_and_in_stock = total_unique_skus - unique_skus_crossdocking_and_in_stock\n",
        "\n",
        "# Criando um gráfico de pizza\n",
        "sizes = [unique_skus_crossdocking_and_in_stock, unique_skus_not_crossdocking_and_in_stock]\n",
        "colors = ['#FF4500', '#FFD833']\n",
        "explode = (0.1, 0)  # Explode 1st slice\n",
        "plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=140)\n",
        "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otv9Aj9cZECk"
      },
      "source": [
        "Assim, é apresentado uma aparente contradição nos dados: enquanto a primeira análise sugere que a maioria das vendas provém de estoque próprio, a análise subsequente mostra que, na realidade, a maior parte das vendas é feita através do crossdocking.\n",
        "\n",
        "Neste terceiro gráfico, é possível concluir que realmente houve a venda de produtos, por crossdocking, que possuíam alta disponibilidade em estoque."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "6xypvwYVZaTk",
        "outputId": "2bcf1037-9037-416a-a000-01c56d122777"
      },
      "outputs": [],
      "source": [
        "#Define a separação por cor\n",
        "colors = df_fixed['shipment_type'].map({'crossdocking': 'turquoise', 'próprio': 'coral'})\n",
        "\n",
        "#Cria o gráfico de dispersão\n",
        "ax = df_fixed.plot.scatter(x='items_sold', y='stock_qty', c=colors, edgecolors='w', linewidth=0.5)\n",
        "\n",
        "#Cria as legendas\n",
        "legend_elements = [Line2D([0], [0], marker='o', color='w', label='Crossdocking', markerfacecolor='turquoise', markersize=5),\n",
        "                   Line2D([0], [0], marker='o', color='w', label='Próprio', markerfacecolor='coral', markersize=5)]\n",
        "ax.legend(handles=legend_elements)\n",
        "\n",
        "#Apresenta o gráfico\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAVg0KrCYNCZ"
      },
      "source": [
        "Conseguimos elaborar duas hipóteses sobre o motivo dessa contradição:\n",
        "* Em algumas situações, um produto pode ter sido vendido em quantidade superior ao estoque disponível e diferente de zero, sendo atendido parcialmente pelo estoque e parcialmente pelo crossdocking. Isso pode levar a classificar a venda inteira como “crossdocking”, distorcendo a representação percentual das vendas e levando à percepção de uma prevalência maior do que realmente existe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LF34SdMWibQN",
        "outputId": "998ab322-7de7-4fc1-c036-15f50864e1a9"
      },
      "outputs": [],
      "source": [
        "vendas_mistas = df_encoded[['shipment_type_crossdocking','items_sold', 'stock_qty']]\n",
        "vendas_mistas[(vendas_mistas['shipment_type_crossdocking'] == 1) & (vendas_mistas['items_sold'] > vendas_mistas['stock_qty']) & (vendas_mistas['stock_qty'] > 1)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIQKfY1_h4EL"
      },
      "source": [
        "* Em outras situações, o processamento da venda via crossdocking ser realizado mesmo havendo estoque disponível pode ser explicado pelo sistema de vendas agendadas. Neste sistema, o produto é enviado diretamente ao cliente no período escolhido por ele, sem passar pelo estoque convencional."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VrfUfcrjh6bS",
        "outputId": "acb228f2-1563-47cb-828c-731479fcf3ca"
      },
      "outputs": [],
      "source": [
        "vendas_agendadas = df_encoded[['shipment_type_crossdocking','items_sold', 'stock_qty']]\n",
        "vendas_agendadas[(vendas_agendadas['shipment_type_crossdocking'] == 1) & (vendas_agendadas['items_sold'] > 0) & (vendas_agendadas['stock_qty'] > 0)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ved8Ej2DfIo1"
      },
      "source": [
        "### Hipótese #2\n",
        "A análise dos gráficos mostra uma tendência curiosa no comportamento dos visitantes do site. Em julho, há um pico de visitas, superado apenas por novembro. Contudo, apesar do grande número de visitantes e dos preços médios mais baixos em julho, o volume de vendas é surpreendentemente baixo. Além disso, julho se destaca por ter muitas visitas e uma grande redução de itens em estoque. Isso levanta a questão: Por que em julho, com alto tráfego e preços reduzidos, as vendas são tão baixas em comparação a outros meses? É necessário investigar as causas desse comportamento atípico."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GydGnLzvh07D"
      },
      "source": [
        "Abaixo é possível analisar a quantidade de vendas e a média de preço dos produtos por mês em um intervalo de 3 anos (2020, 2021, 2022). Nota-se que em julho as vendas e os preços são baixos.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fYTNx7kfIpR",
        "outputId": "5f63ff76-4810-4c0b-ba4d-20eb7894cbb9"
      },
      "outputs": [],
      "source": [
        "\n",
        "df_items_sold = df_final[['mes', 'items_sold']]\n",
        "grouped_items_sold = df_items_sold.groupby('mes').sum()\n",
        "\n",
        "df_filtered_price = df_dates_fixed[['mes', 'unit_price']]\n",
        "grouped_data_price = df_filtered_price.groupby('mes').mean()\n",
        "\n",
        "df_filtered_stock = df_final[['mes', 'stock_qty']]\n",
        "grouped_data_stock = df_filtered_stock.groupby('mes').mean()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "line1, = plt.plot(grouped_items_sold.index, grouped_items_sold['items_sold'], marker='o', linestyle='-', color='orange', label='Quantidade de Vendas')\n",
        "plt.xlabel('Meses')\n",
        "plt.ylabel('Quantidade Vendas')\n",
        "plt.title('Preço Médio/Quantidade de Vendas Vs Meses ')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.xticks(list(range(1, 13)), list(range(1, 13)))\n",
        "ax2 = plt.gca().twinx()\n",
        "line2, = ax2.plot(grouped_data_price.index, grouped_data_price['unit_price'], marker='o', linestyle='-', color='green', label='Preço Médio')\n",
        "ax2.set_ylabel('Preço Médio')\n",
        "\n",
        "lines = [line1, line2]\n",
        "labels = [l.get_label() for l in lines]\n",
        "plt.legend(lines, labels, loc='upper left')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MUJxUPfidNT"
      },
      "source": [
        "Abaixo é possível analisar a média da quantidade no estoque e as visitas no site por mês em um intervalo de 3 anos (2020, 2021, 2022). Nota-se que curiosamente as visitas no site estão muito altas, enquanto o estoque, os preços, e as vendas estão em baixa.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLmUxHKoii14",
        "outputId": "eb0cab7d-1502-484e-9e63-7ae88d8dcca1"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Filtrando o DataFrame para pegar apenas as colunas relevantes para a primeira análise\n",
        "df_items_sold = df_final[['mes', 'avg_website_visits_last_week']]\n",
        "# Agrupando os dados por 'mes' e calcule a soma dos items vendidos\n",
        "grouped_items_sold = df_items_sold.groupby('mes').sum()\n",
        "\n",
        "# Filtrando o DataFrame para pegar apenas as colunas relevantes para a segunda análise\n",
        "df_filtered_price = df_dates_fixed[['mes', 'stock_qty']]\n",
        "# Agrupando os dados por 'mes' e calcule a média do 'unit_price'\n",
        "grouped_data_price = df_filtered_price.groupby('mes').mean()\n",
        "\n",
        "# Filtrando o DataFrame para pegar apenas as colunas relevantes para a terceira análise\n",
        "df_filtered_stock = df_final[['mes', 'stock_qty']]\n",
        "# Agrupando os dados por 'mes' e calcule a média do 'stock_qty'\n",
        "grouped_data_stock = df_filtered_stock.groupby('mes').mean()\n",
        "\n",
        "# Criando um gráfico de linha juntando todas as informações\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Primeiro eixo y (esquerdo)\n",
        "line1, = plt.plot(grouped_items_sold.index, grouped_items_sold['avg_website_visits_last_week'], marker='o', linestyle='-', color='blue', label='Visitas no Site')\n",
        "plt.xlabel('Meses')\n",
        "plt.ylabel('Visitas no Site')\n",
        "plt.title('Visitas no Site/Média quantidade no Estoque vs Meses')\n",
        "plt.grid(True)\n",
        "\n",
        "# Ajustando os ticks do eixo x\n",
        "plt.xticks(list(range(1, 13)), list(range(1, 13)))\n",
        "\n",
        "# Criando um segundo eixo y à direita\n",
        "ax2 = plt.gca().twinx()\n",
        "line2, = ax2.plot(grouped_data_price.index, grouped_data_price['stock_qty'], marker='o', linestyle='-', color='red', label='Média Quantidade no Estoque')\n",
        "ax2.set_ylabel('Média Quantidade no Estoque')\n",
        "\n",
        "# Combinando as legendas\n",
        "lines = [line1, line2]\n",
        "labels = [l.get_label() for l in lines]\n",
        "plt.legend(lines, labels, loc='upper left')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7y24daiIkDEN"
      },
      "source": [
        "Conseguimos elaborar uma hipótese sobre o motivo dessa contradição:\n",
        "\n",
        "* Julho é um mês em que muitas empresas fazem liquidações devido à sua posição estratégica no calendário comercial, oferecendo promoções e descontos. Essas ofertas aumentam o tráfego em sites de e-commerce e atraem muitos consumidores. No entanto, surge o desafio da gestão de estoque. Se produtos desejados pelos clientes não estiverem disponíveis, mesmo com preços reduzidos, isso pode afetar negativamente as vendas, frustrando os compradores. Assim, é vital uma boa gestão de estoque durante essas promoções para atender à demanda e garantir a satisfação do cliente.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRK85y7Ix4jW"
      },
      "source": [
        "### Hipótese #3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nNVpnGq5mCwI"
      },
      "source": [
        "Os gráficos que relacionam \"preço\" e \"vendas\" nos anos de 2020, 2021 e 2022 revelam uma tendência notável. Nos primeiros dois anos, as vendas aumentaram proporcionalmente aos preços, indicando uma relação direta entre eles. No entanto, em 2022, essa tendência mudou, com as vendas diminuindo à medida que os preços aumentavam e vice-versa. Esse novo padrão levanta questionamentos sobre por que as vendas se elevaram em 2020 e 2021, apesar dos aumentos nos preços, enquanto o oposto ocorreu em 2022. Assim, foram propostas hipóteses para explicar essa mudança."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NO88blkmW30"
      },
      "source": [
        "Abaixo é possível analisar a quantidade de vendas e a média de preço dos produtos no ano de 2020. Nota-se que os preços e vendas tendem a seguir mejoritariamente a mesma linha de cresciemento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-eN-kcxfneZ",
        "outputId": "50ca1080-d2a0-4792-bdf1-fdeb65f4c7bb"
      },
      "outputs": [],
      "source": [
        "sold_2020 = df_encoded.loc[df_encoded['ano'] == 2020]\n",
        "df_items_sold = sold_2020[['mes', 'items_sold']]\n",
        "grouped_items_sold = df_items_sold.groupby('mes').sum()\n",
        "\n",
        "price_2020 = df_dates_fixed.loc[df_dates_fixed['ano'] == 2020]\n",
        "df_filtered_price = price_2020[['mes', 'unit_price']]\n",
        "grouped_data_price = df_filtered_price.groupby('mes').mean()\n",
        "\n",
        "df_filtered_stock = df_encoded[['mes', 'unit_price']]\n",
        "grouped_data_stock = df_filtered_stock.groupby('mes').mean()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "line1, = plt.plot(grouped_items_sold.index, grouped_items_sold['items_sold'], marker='o', linestyle='-', color='blue', label='Média de vendas')\n",
        "plt.xlabel('Meses')\n",
        "plt.ylabel('Média de vendas por sku')\n",
        "plt.title('Preço/Vendas x 2020')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.xticks(list(range(1, 13)), list(range(1, 13)))\n",
        "ax2 = plt.gca().twinx()\n",
        "line2, = ax2.plot(grouped_data_price.index, grouped_data_price['unit_price'], marker='o', linestyle='-', color='red', label='Média de preço')\n",
        "ax2.set_ylabel('Preço médio por sku')\n",
        "\n",
        "lines = [line1, line2]\n",
        "labels = [l.get_label() for l in lines]\n",
        "\n",
        "plt.legend(lines, labels, loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJj3ZJR7n3RU"
      },
      "source": [
        "Abaixo é possível analisar a quantidade de vendas e a média de preço dos produtos no ano de 2021. Nota-se novamente que os preços e vendas tendem a seguir mejoritariamente a mesma linha de cresciemento.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnpWNCeappU9",
        "outputId": "09cfdc68-48cc-4aab-f37f-cdf7d1a73ed4"
      },
      "outputs": [],
      "source": [
        "\n",
        "sold_2020 = df_encoded.loc[df_encoded['ano'] == 2021]\n",
        "df_items_sold = sold_2020[['mes', 'items_sold']]\n",
        "grouped_items_sold = df_items_sold.groupby('mes').sum()\n",
        "\n",
        "price_2020 = df_dates_fixed.loc[df_dates_fixed['ano'] == 2021]\n",
        "df_filtered_price = price_2020[['mes', 'unit_price']]\n",
        "grouped_data_price = df_filtered_price.groupby('mes').mean()\n",
        "\n",
        "df_filtered_stock = df_encoded[['mes', 'unit_price']]\n",
        "grouped_data_stock = df_filtered_stock.groupby('mes').mean()\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "line1, = plt.plot(grouped_items_sold.index, grouped_items_sold['items_sold'], marker='o', linestyle='-', color='blue', label='Média de vendas')\n",
        "plt.xlabel('Meses')\n",
        "plt.ylabel('Média de vendas por sku')\n",
        "plt.title('Preço/Vendas x 2021')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.xticks(list(range(1, 13)), list(range(1, 13)))\n",
        "ax2 = plt.gca().twinx()\n",
        "\n",
        "line2, = ax2.plot(grouped_data_price.index, grouped_data_price['unit_price'], marker='o', linestyle='-', color='red', label='Média de preço')\n",
        "ax2.set_ylabel('Preço médio por sku')\n",
        "lines = [line1, line2]\n",
        "labels = [l.get_label() for l in lines]\n",
        "\n",
        "plt.legend(lines, labels, loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ee74nbSeoFHU"
      },
      "source": [
        "Abaixo é possível analisar a quantidade de vendas e a média de preço dos produtos no ano de 2022. Diferentemente dos anos anteriores nota-se que os preços e vendas tiveram um crescimento inversamente proporcional, ou seja, enquanto um aumentava o outro diminuia seu valor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12PB3Zrepwr0",
        "outputId": "21672639-73fc-44cf-c440-316870722fdc"
      },
      "outputs": [],
      "source": [
        "sold_2020 = df_encoded.loc[df_encoded['ano'] == 2022]\n",
        "df_items_sold = sold_2020[['mes', 'items_sold']]\n",
        "grouped_items_sold = df_items_sold.groupby('mes').sum()\n",
        "\n",
        "price_2020 = df_dates_fixed.loc[df_dates_fixed['ano'] == 2022]\n",
        "df_filtered_price = price_2020[['mes', 'unit_price']]\n",
        "grouped_data_price = df_filtered_price.groupby('mes').mean()\n",
        "\n",
        "df_filtered_stock = df_encoded[['mes', 'unit_price']]\n",
        "grouped_data_stock = df_filtered_stock.groupby('mes').mean()\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "line1, = plt.plot(grouped_items_sold.index, grouped_items_sold['items_sold'], marker='o', linestyle='-', color='blue', label='Média de vendas')\n",
        "plt.xlabel('Meses')\n",
        "plt.ylabel('Média de vendas por sku')\n",
        "plt.title('Preço/Vendas x 2022')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.xticks(list(range(1, 13)), list(range(1, 13)))\n",
        "ax2 = plt.gca().twinx()\n",
        "\n",
        "line2, = ax2.plot(grouped_data_price.index, grouped_data_price['unit_price'], marker='o', linestyle='-', color='red', label='Média de preço')\n",
        "ax2.set_ylabel('Preço médio por sku')\n",
        "lines = [line1, line2]\n",
        "labels = [l.get_label() for l in lines]\n",
        "\n",
        "plt.legend(lines, labels, loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLz3vjnvpS2w"
      },
      "source": [
        "Conseguimos elaborar uma hipótese sobre o motivo dessa quebra no padrão de crescimento:\n",
        "\n",
        "Fatores Macroeconômicos: Nos anos de 2020 e 2021, a pandemia de COVID-19 causou um aumento significativo no valor do dólar, elevando os preços das matérias-primas e, consequentemente, dos produtos da Mobly. A alta inflação nesse período também impactou os valores. Essas razões explicam o aumento nos preços mostrado nos gráficos de 2020 e 2021.\n",
        "\n",
        "Impacto da Quarentena: A pandemia impulsionou a adoção do trabalho remoto, levando as pessoas a investirem em móveis para melhorar seus espaços domésticos. Isso resultou em uma demanda crescente por móveis, explicando o aumento nas vendas em 2020 e 2021.\n",
        "\n",
        "Retomada Econômica e Normalização: Em 2022, a economia brasileira retomou suas atividades, levando à estabilidade dos preços e dos indicadores macroeconômicos. A menor demanda por móveis pós-pandemia levou a vendas estáveis. As vendas parecem ter sido sensíveis aos preços, aumentando quando os preços eram acessíveis e vice-versa. Isso pode explicar a quebra do padrão observado anteriormente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1O-uR6aG0ZZz"
      },
      "source": [
        "#Gráficos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXgQikrF0e4l"
      },
      "source": [
        "###Gráfico de relação das vendas mensais nos anos de 2020 a 2022"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "buum7n3ASxVk",
        "outputId": "5259e2cd-507a-442f-b065-40d065c4fa48"
      },
      "outputs": [],
      "source": [
        "df_final2 = df_final[df_final['ano'] != 2023]\n",
        "monthly_sales = df_final2.groupby(['mes', 'ano'])['items_sold'].sum().reset_index()\n",
        "fig = px.line(monthly_sales, x='mes', y='items_sold', animation_frame='ano')\n",
        "fig.layout.updatemenus[0].buttons[0].args[1]['frame']['duration'] = 2000\n",
        "fig.layout.updatemenus[0].buttons[0].args[1]['transition']['duration'] = 8000\n",
        "fig.update_layout(title='Total de vendas mensais por ano de 2020 a 2022')\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMjW65xA1Mux"
      },
      "source": [
        "Este gráfico representa o número de itens vendidos por mês, durante os 3 últimos anos (2020, 2021 e 2022).\n",
        "\n",
        "Uma das características observadas nessa progressão foi aumento de vendas ao longo de três anos, que pode ser explicado por ser o crescimento da economia e do poder de compra dos consumidores, o que aumenta a demanda por produtos, aumento da popularidade da Mobly e a expansão de sua base de clientes. Além disso, existe um impacto muito grande da pandemia sobre as vendas online, que se tornaram mais comuns no cotidiano.\n",
        "\n",
        "A segunda observação recorre à tendência de estabilização geral do gráfico de vendas ao longo dos anos, que pode ser atribuída à consistência na oferta de produtos e serviços pela Mobly. A empresa pode ter mantido uma estratégia de vendas consistente ao longo de três anos, o que resultou em flutuações suaves nas vendas.\n",
        "\n",
        "Por último, foi analisado um pico de vendas em novembro pode ser explicado pela proximidade das festas de fim de ano e a Black Friday, principalmente. Durante esse período, muitas pessoas começam a comprar presentes para amigos e familiares, o que aumenta a demanda por produtos e é um período em que empresas realizam promoções e descontos durante esse período para atrair mais clientes, o que pode contribuir para o aumento das vendas.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjYa0SBagJ_-"
      },
      "source": [
        "###Gráfico de soma das visitas médias ao site por dia da semana"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "NT0gkOi9gO6-",
        "outputId": "11d4decb-7786-4213-ba2e-c458c399dd56"
      },
      "outputs": [],
      "source": [
        "monthly_sales = df_fixed.groupby(['weekday_name'])['avg_website_visits_last_week'].sum().reset_index()\n",
        "dias_da_semana = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
        "monthly_sales['weekday_name'] = pd.Categorical(monthly_sales['weekday_name'], categories=dias_da_semana, ordered=True)\n",
        "monthly_sales = monthly_sales.sort_values('weekday_name')\n",
        "fig = px.bar(monthly_sales, x='weekday_name', y='avg_website_visits_last_week')\n",
        "fig.update_layout(title='Soma das visitas médias ao site por dia da semana')\n",
        "fig.update_yaxes(range=[12780000, 12880000])\n",
        "fig.update_traces(marker_color='#FF9345')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51NnxBja0LWE"
      },
      "source": [
        "A representação ilustra a distribuição da soma da média de visitantes no site durante os dias da semana.\n",
        "\n",
        "Percebe-se que existem três tendências de visitas no site, uma em relação à baixa durante a terça-feira, outra sobre a estabilidade no final de semana e a última sobre a alta na segunda-feira.\n",
        "\n",
        "A tendência de baixa nas terças-feiras pode ser explicada porque durante os dias úteis, as pessoas tendem a estar mais ocupadas com o trabalho e outras responsabilidades, o que pode diminuir o tempo disponível para navegar em sites de compras.\n",
        "\n",
        "Durante o fim de semana, as pessoas geralmente têm mais tempo livre para se dedicar a atividades de lazer, incluindo navegar em sites de compras.\n",
        "\n",
        "Já o aumento de visitas nas segundas-feiras pode ser explicado pelo fenômeno do ‘Efeito Segunda-feira’. Esse efeito se refere à tendência das pessoas de retornar ao trabalho após o fim de semana com uma atitude mais positiva e produtiva. Isso pode levar a um aumento na busca por atualizações e novidades, incluindo visitas a sites de compras.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eR8cmgLC0e4l"
      },
      "source": [
        "### Gráfico de dispersão de preço unitário vs itens vendidos, separados por categoria de produto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "91e4sUMjI4-2",
        "outputId": "40ca9a25-e412-4122-94b8-77c3035d21c4"
      },
      "outputs": [],
      "source": [
        "fig = px.scatter(df_fixed, x='items_sold', y='unit_price', color='product_category')\n",
        "fig.update_layout(\n",
        "    title='Gráfico de dispersão de preço unitário vs itens vendidos',\n",
        "    xaxis_title='Itens vendidos',\n",
        "    yaxis_title='Preço unitário'\n",
        ")\n",
        "fig.update_traces(marker=dict(opacity=0.3))\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgkK_h05pVHL"
      },
      "source": [
        "Versão mais leve do mesmo gráfico:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "Fx3RFVzjMUr7",
        "outputId": "6418dab8-a17e-4dbf-d4e0-56ec485115f4"
      },
      "outputs": [],
      "source": [
        "color_map = {'Sala de Estar': 'red', 'Quarto': 'blue', 'Sala de Jantar': 'green', 'Escritório': 'orange', 'Cozinha': 'purple', 'Móveis Gamer': 'chocolate', 'Área Externa': 'hotpink', 'Jardim ': 'slategray', 'Móveis Infantis': 'gold', 'Móveis ': 'cyan', 'Quarto Infantil Decorado': 'cadetblue', 'Tapetes': 'olive', 'Colchões': 'coral', 'Lavanderia': 'silver', 'Acessórios para Cama': 'turquoise', 'Espelhos': 'violet'}\n",
        "\n",
        "colors = df_fixed['product_category'].map(color_map)\n",
        "\n",
        "ax = df_fixed.plot.scatter(x='items_sold', y='unit_price', edgecolor='w', c=colors, linewidth=0.5)\n",
        "\n",
        "legend_elements = []\n",
        "for category, color in color_map.items():\n",
        "    legend_elements.append(Line2D([0], [0], marker='o', color='w', label=category, markerfacecolor=color, markersize=5))\n",
        "\n",
        "ax.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(1, 0.5))\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P84Z6Wtp02RH"
      },
      "source": [
        "A representação procura adequar a relação entre preço unitário dos produtos e a quantidade destes itens vendidos.\n",
        "\n",
        "Sobre esta dispersão, há 2 observações: a primeira é de que as maiores vendas ocorrem quando o preço unitário é mais baixo e pode ser explicada pela lei da oferta e da demanda. Quando o preço de um produto é reduzido, é natural que a demanda por ele aumente, já que mais pessoas podem ter acesso a ele. Isso pode levar a um aumento nas vendas, já que mais consumidores estão dispostos a comprar o produto a um preço mais baixo.\n",
        "\n",
        "Já a segunda é a tendência de valorização no preço unitário dos móveis da categoria sala de jantar pode ser atribuída ao fator de salas de jantar serem mais comuns especificamente em casas com maior área, que remetem à um poder aquisitivo mais elevado, justificando esse valor a ser pago por produtos da classe, além disso, existem produtos dessa classe que são importados, o que aumenta seu preço de forma substancial."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsytxBBM9Ao1",
        "outputId": "b07123ee-f52b-4c9c-9517-8f84b3b101e3"
      },
      "outputs": [],
      "source": [
        "\n",
        "df_final.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0Bua2Y59Ao1"
      },
      "source": [
        "# Preparação dos dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4ecLBcg9Ao1"
      },
      "source": [
        "### Seleção das features para o modelo de machine learning\n",
        "---\n",
        "Uma das etapas cruciais na construção de um modelo de machine learning é a seleção criteriosa das características (features) que servirão como entrada para o modelo. Cada feature foi selecionada com base em sua relevância para o problema em questão, e essa decisão é fundamental para garantir que nosso modelo seja capaz de aprender com eficácia e gerar previsões precisas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tF2XEIYh9Ao1"
      },
      "source": [
        "### Divisão do conjunto de treino e de teste\n",
        "---\n",
        "Para avaliar a capacidade de generalização do modelo, é necessário dividir o conjunto de dados em dois subconjuntos: treino e teste. O conjunto de treino é utilizado para treinar o modelo, enquanto o conjunto de teste é utilizado para avaliar o desempenho do modelo em dados não vistos anteriormente. Essa divisão é importante para evitar que o modelo memorize os dados de treino e não seja capaz de generalizar para novos dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4LvgfcB9Ao2"
      },
      "source": [
        "### Escalonamento das features\n",
        "---\n",
        "O escalonamento é uma etapa importante, pois garante que as features estejam na mesma escala, o que facilita o processo de aprendizagem do modelo. Para isso, utilizamos o StandardScaler, que padroniza as features removendo a média e escalonando para a variância unitária. Dessa forma, as features são transformadas de modo que sua distribuição tenha uma média igual a 0 e um desvio padrão igual a 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhtCAZdR9Ao2"
      },
      "source": [
        "# Modelo de _Machine Learning_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ofy_kcqX9Ao2"
      },
      "source": [
        "# Modelos supervisonados de regressão\n",
        "---\n",
        "Os modelos de regressão são utilizados para prever valores contínuos, como por exemplo, o preço de um imóvel ou a quantidade de vendas de um produto. Neste projeto, utilizamos os seguintes modelos de regressão:\n",
        "* Random Forest Regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9F7dwmE9Ao2"
      },
      "source": [
        "Random Forest Regressor\n",
        "---\n",
        "O Random Forest Regressor é um modelo de aprendizado de máquina que utiliza o método de florestas aleatórias para realizar a regressão. Esse modelo é uma extensão do Random Forest Classifier, que é um modelo de classificação. O Random Forest Regressor é um modelo muito poderoso, que apresenta um bom desempenho na maioria dos problemas de regressão. Além disso, ele é capaz de lidar com dados ausentes e valores discrepantes, o que é uma grande vantagem em relação a outros modelos de regressão."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KA4wAsed-nHX"
      },
      "source": [
        "###Seleção das melhores features para o modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zt5Oiz5k9Vm5"
      },
      "outputs": [],
      "source": [
        "# Todas as features para testagem\n",
        "# Há a remoção de 'items_sold' e 'items_sold_bundle' pois são tanto o target como um de seus subconjuntos\n",
        "features = [ 'stock_qty', 'dollar_quotation'\n",
        "       'shipment_type_crossdocking', 'shipment_type_próprio',\n",
        "       'product_department_Cama e Banho', 'product_department_Decoração',\n",
        "       'product_department_Gamer', 'product_department_Infantil',\n",
        "       'product_department_Keva', 'product_department_Móveis',\n",
        "       'origin_country_Importado', 'origin_country_Nacional',\n",
        "       'process_costing_no', 'process_costing_yes',\n",
        "       'flag_bundle_SKU vendido em conjunto ou sozinho',\n",
        "       'flag_bundle_SKU vendido somente sozinho', 'color_encoded',\n",
        "       'sku_encoded', 'anchor_category_encoded', 'product_category_encoded',\n",
        "       'ano', 'mes', 'dia', 'dia_da_semana', 'semana_do_ano', 'trimestre',\n",
        "       'dia_do_ano', 'eh_fim_de_semana', 'avg_website_visits_last_week',\n",
        "       'sku_height', 'sku_width', 'sku_length', 'sku_weight', 'unit_price',\n",
        "       'supplier_delivery_time']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WO2wzz5Z9Vm6"
      },
      "outputs": [],
      "source": [
        "#Criando um dataframe a partir do df_final, com todas as colunas como feature\n",
        "# Pegando uma amostragem de apenas 160 mil linhas\n",
        "n = 160000\n",
        "df_parameters_sampled = df_final.drop(df_final.columns.difference(features), 1).sample(n,random_state = 42)\n",
        "\n",
        "# Separando as variáveis independentes e dependentes (X e Y)\n",
        "X2 = df_parameters_sampled\n",
        "y2 = df_final['items_sold'].sample(n,random_state = 42)\n",
        "# Dividindo o conjunto de dados em conjuntos de treinamento e teste\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=95)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_wNrSwR79Vm6"
      },
      "outputs": [],
      "source": [
        "# Normalizando as features (escalando para média 0 e desvio padrão 1)\n",
        "scaler = StandardScaler()\n",
        "X2_train = scaler.fit_transform(X2_train)\n",
        "X2_test = scaler.transform(X2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NlSNZAHl9Vm6",
        "outputId": "e575501c-f901-4232-8332-c2394a8a474f"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestRegressor()\n",
        "scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
        "rfe = RFECV(rf, step=1, cv=5, scoring=scorer, n_jobs=-1)\n",
        "rfe = rfe.fit(X2_train, y2_train)\n",
        "print(\"Feature ranking: \", rfe.ranking_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5EldRbW9Vm6",
        "outputId": "acd88372-79ea-46a7-9ef2-d1ed2a4573de"
      },
      "outputs": [],
      "source": [
        "mask = rfe.get_support()\n",
        "\n",
        "# Convertendo a mascara para um array de numpy para indexação\n",
        "mask = np.array(mask)\n",
        "\n",
        "# Usando indexação booleana para pegar as features selecionadas\n",
        "best_features = [feature for i, feature in enumerate(features) if mask[i]]\n",
        "\n",
        "print(\"All features: \", X2.shape[1])\n",
        "print(features)\n",
        "\n",
        "print(\"Selected best: \", len(best_features))\n",
        "print(best_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cELS7Gnz-3N0"
      },
      "source": [
        "###Seleção dos melhores parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NB3k_Ciq9Vm6"
      },
      "outputs": [],
      "source": [
        "# Features escolhidas anteriormente para o modelo\n",
        "features = ['product_department_Cama e Banho',  'sku_encoded', 'anchor_category_encoded', 'ano', 'dia_da_semana', 'semana_do_ano', 'dia_do_ano', 'avg_website_visits_last_week', 'sku_height', 'sku_width', 'sku_length', 'sku_weight', 'unit_price', ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1006Z5e9Vm6"
      },
      "outputs": [],
      "source": [
        "#Criando um dataframe a partir do df_final, mas somente com as colunas das features definidas\n",
        "# Pegando uma amostragem de apenas 160 mil linhas\n",
        "n = 160000\n",
        "df_parameters_sampled = df_final.drop(df_final.columns.difference(features), 1).sample(n,random_state = 42)\n",
        "\n",
        "# Separando as variáveis independentes e dependentes (X e Y)\n",
        "X2 = df_parameters_sampled\n",
        "y2 = df_final['items_sold'].sample(n,random_state = 42)\n",
        "\n",
        "# Dividindo o conjunto de dados em conjuntos de treinamento e teste\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=95)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJwgB8Hj9Vm7"
      },
      "outputs": [],
      "source": [
        "#Criando um dataframe a partir do df_final, agora readaptado para as features selecionadas\n",
        "df_parameters = df_final.drop(df_final.columns.difference(features), 1)\n",
        "\n",
        "# Separando as variáveis independentes e dependentes (X e Y)\n",
        "X = df_parameters\n",
        "y = df_final['items_sold']\n",
        "# Dividindo o conjunto de dados em conjuntos de treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=95)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMZ8_iKf9Vm7"
      },
      "outputs": [],
      "source": [
        "# Normalizando as features (escalando para média 0 e desvio padrão 1)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "X2_train = scaler.fit_transform(X2_train)\n",
        "X2_test = scaler.transform(X2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09_idcJQ9Vm7"
      },
      "outputs": [],
      "source": [
        "# Criando a grid de parâmetros a serem testados\n",
        "param_grid = {\n",
        "    'n_estimators': [150,200,250],\n",
        "    'max_depth': [10,15,20],\n",
        "}\n",
        "\n",
        "# Definindo o modelo a ser testado\n",
        "rf_regressor = RandomForestRegressor()\n",
        "\n",
        "# Definindo o \"score\" para avaliarmos qual será a melhor combinação de hiperparâmetros para o modelo\n",
        "scorer = make_scorer(mean_squared_error, greater_is_better=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXFZuZ7-9Vm7"
      },
      "outputs": [],
      "source": [
        "# Realizando o grid search (remover n_jobs = -1 caso não queira usar todos os cores do computador)\n",
        "grid_search = GridSearchCV(estimator=rf_regressor, param_grid=param_grid, cv=5,scoring=scorer, n_jobs=-1, refit=True)\n",
        "\n",
        "grid_search.fit(X2_train, y2_train)\n",
        "\n",
        "print(\"Melhores Hiperparâmetros: \", grid_search.best_params_)\n",
        "\n",
        "# Conseguindo os melhores estimadores\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "\n",
        "print('Best Model', best_rf_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykWCZY6S-9in"
      },
      "source": [
        "###Aplicação do modelo com os hiperparâmetros e features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GPX7oXC-9Vm7"
      },
      "outputs": [],
      "source": [
        "# Instanciando o modelo com os hiperparâmetros definidos\n",
        "rf = RandomForestRegressor()\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "#Gerando as predições\n",
        "predictions = rf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6did0aq_Fs5"
      },
      "outputs": [],
      "source": [
        "#Métrica do Erro Quadrático Médio\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "\n",
        "#Métrica da Raiz Quadrada do Erro Médio\n",
        "RMSE = np.sqrt(mse)\n",
        "print('RMSE:', RMSE)\n",
        "\n",
        "#Métrica do Coeficiente de Determinação R² score\n",
        "r2 = r2_score(y_test, predictions)\n",
        "print(\"R2 score:\", r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTUwiOmg9Ao2"
      },
      "source": [
        "Gradient Boosting Regressor\n",
        "---\n",
        "adaasdasdasdasdasasdasdas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjHkNmLG9Ao3"
      },
      "outputs": [],
      "source": [
        "# Todas as features para testagem\n",
        "# Há a remoção de 'items_sold' e 'items_sold_bundle' pois são tanto o target como um de seus subconjuntos\n",
        "features = [ 'stock_qty', 'dollar_quotation'\n",
        "       'shipment_type_crossdocking', 'shipment_type_próprio',\n",
        "       'product_department_Cama e Banho', 'product_department_Decoração',\n",
        "       'product_department_Gamer', 'product_department_Infantil',\n",
        "       'product_department_Keva', 'product_department_Móveis',\n",
        "       'origin_country_Importado', 'origin_country_Nacional',\n",
        "       'process_costing_no', 'process_costing_yes',\n",
        "       'flag_bundle_SKU vendido em conjunto ou sozinho',\n",
        "       'flag_bundle_SKU vendido somente sozinho', 'color_encoded',\n",
        "       'sku_encoded', 'anchor_category_encoded', 'product_category_encoded',\n",
        "       'ano', 'mes', 'dia', 'dia_da_semana', 'semana_do_ano', 'trimestre',\n",
        "       'dia_do_ano', 'eh_fim_de_semana', 'avg_website_visits_last_week',\n",
        "       'sku_height', 'sku_width', 'sku_length', 'sku_weight', 'unit_price',\n",
        "       'supplier_delivery_time']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5RV8e6B9Ao4",
        "outputId": "a077ce51-d07b-4839-a671-09881b9f1555"
      },
      "outputs": [],
      "source": [
        "#Criando um dataframe a partir do df_final, com todas as colunas como feature\n",
        "# Pegando uma amostragem de apenas 160 mil linhas\n",
        "n = 160000\n",
        "df_parameters_sampled = df_final.drop(df_final.columns.difference(features), 1).sample(n,random_state = 42)\n",
        "\n",
        "# Separando as variáveis independentes e dependentes (X e Y)\n",
        "X2 = df_parameters_sampled\n",
        "y2 = df_final['items_sold'].sample(n,random_state = 42)\n",
        "# Dividindo o conjunto de dados em conjuntos de treinamento e teste\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=95)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWOLrDWs9Ao5"
      },
      "outputs": [],
      "source": [
        "# Normalizando as features (escalando para média 0 e desvio padrão 1)\n",
        "scaler = StandardScaler()\n",
        "X2_train = scaler.fit_transform(X2_train)\n",
        "X2_test = scaler.transform(X2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ej4esLSc9Ao5",
        "outputId": "e575501c-f901-4232-8332-c2394a8a474f"
      },
      "outputs": [],
      "source": [
        "clf = GradientBoostingRegressor()\n",
        "scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
        "rfe = RFECV(clf, step=1, cv=5, scoring=scorer, n_jobs=-1)\n",
        "rfe = rfe.fit(X2_train, y2_train)\n",
        "print(\"Feature ranking: \", rfe.ranking_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6ZBmTSU9Ao5",
        "outputId": "acd88372-79ea-46a7-9ef2-d1ed2a4573de"
      },
      "outputs": [],
      "source": [
        "mask = rfe.get_support()\n",
        "\n",
        "# Convertendo a mascara para um array de numpy para indexação\n",
        "mask = np.array(mask)\n",
        "\n",
        "# Usando indexação booleana para pegar as features selecionadas\n",
        "best_features = [feature for i, feature in enumerate(features) if mask[i]]\n",
        "\n",
        "print(\"All features: \", X2.shape[1])\n",
        "print(features)\n",
        "\n",
        "print(\"Selected best: \", len(best_features))\n",
        "print(best_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00gDfezL9Ao6"
      },
      "outputs": [],
      "source": [
        "# Features escolhidas anteriormente para o modelo\n",
        "features = ['product_department_Cama e Banho',  'sku_encoded', 'anchor_category_encoded', 'ano', 'dia_da_semana', 'semana_do_ano', 'dia_do_ano', 'avg_website_visits_last_week', 'sku_height', 'sku_width', 'sku_length', 'sku_weight', 'unit_price', ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJ3H75Db9Ao6",
        "outputId": "44dc9bdb-2205-494d-e8d3-cad7c96568a9"
      },
      "outputs": [],
      "source": [
        "#Criando um dataframe a partir do df_final, mas somente com as colunas das features definidas\n",
        "# Pegando uma amostragem de apenas 160 mil linhas\n",
        "n = 160000\n",
        "df_parameters_sampled = df_final.drop(df_final.columns.difference(features), 1).sample(n,random_state = 42)\n",
        "\n",
        "# Separando as variáveis independentes e dependentes (X e Y)\n",
        "X2 = df_parameters_sampled\n",
        "y2 = df_final['items_sold'].sample(n,random_state = 42)\n",
        "# Dividindo o conjunto de dados em conjuntos de treinamento e teste\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=95)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SRDC6IV9Ao6",
        "outputId": "98fc8994-321f-4342-e3e4-216777510444"
      },
      "outputs": [],
      "source": [
        "#Criando um dataframe a partir do df_final, agora readaptado para as features selecionadas\n",
        "df_parameters = df_final.drop(df_final.columns.difference(features), 1)\n",
        "\n",
        "# Separando as variáveis independentes e dependentes (X e Y)\n",
        "X = df_parameters\n",
        "y = df_final['items_sold']\n",
        "# Dividindo o conjunto de dados em conjuntos de treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=95)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0_GcsNn9Ao7"
      },
      "outputs": [],
      "source": [
        "# Normalizando as features (escalando para média 0 e desvio padrão 1)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "X2_train = scaler.fit_transform(X2_train)\n",
        "X2_test = scaler.transform(X2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLTSERHJ9Ao7"
      },
      "outputs": [],
      "source": [
        "# Criando a grid de parâmetros a serem testados\n",
        "param_grid = {\n",
        "    'n_estimators': [230,250,270],\n",
        "    'max_depth': [8,10,12],\n",
        "    'learning_rate': [00.07,0.08,0.09]\n",
        "}\n",
        "\n",
        "# Definindo o modelo a ser testado\n",
        "gb_regressor = GradientBoostingRegressor()\n",
        "\n",
        "# Definindo o \"score\" para avaliarmos qual será a melhor combinação de hiperparâmetros para o modelo\n",
        "scorer = make_scorer(mean_squared_error, greater_is_better=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVzKx0oJ9Ao7",
        "outputId": "3caf1acb-3f0e-4072-8b37-dc6a0737f624"
      },
      "outputs": [],
      "source": [
        "# Realizando o grid search (remover n_jobs = -1 caso não queira usar todos os cores do computador)\n",
        "grid_search = GridSearchCV(estimator=gb_regressor, param_grid=param_grid, cv=5,scoring=scorer, n_jobs=-1, refit=True)\n",
        "\n",
        "grid_search.fit(X2_train, y2_train)\n",
        "\n",
        "print(\"Melhores Hiperparâmetros: \", grid_search.best_params_)\n",
        "\n",
        "# Conseguindo os melhores estimadores\n",
        "best_gb_model = grid_search.best_estimator_\n",
        "\n",
        "print('Best Model', best_gb_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AusZRzLu9Ao8",
        "outputId": "271c95ba-8069-4820-ec95-10ef5ecc636a"
      },
      "outputs": [],
      "source": [
        "# Instanciando o modelo com os hiperparâmetros definidos\n",
        "gbr = GradientBoostingRegressor(n_estimators=270,max_depth=10,learning_rate=0.09)\n",
        "gbr.fit(X_train, y_train)\n",
        "\n",
        "#Gerando as predições\n",
        "predictions = gbr.predict(X_test)\n",
        "\n",
        "#Métrica do Erro Quadrático Médio\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "\n",
        "#Métrica da Raiz Quadrada do Erro Médio\n",
        "RMSE = np.sqrt(mse)\n",
        "print('RMSE:', RMSE)\n",
        "\n",
        "#Métrica do Coeficiente de Determinação R² score\n",
        "r2 = r2_score(y_test, predictions)\n",
        "print(\"R2 score:\", r2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extreme Gradient Boosting Regressor(XGBoost)\n",
        "---\n",
        "O XGBoost (Extreme Gradient Boosting) é um algoritmo de aprendizado de máquina usado para problemas de regressão. Ele funciona construindo uma série de árvores de decisão, cada uma corrigindo os erros da árvore anterior. As árvores são ponderadas e combinadas para prever valores contínuos, tornando-o eficaz para modelar relações complexas entre variáveis e prever resultados numéricos com precisão."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Seleção das melhores features para o modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Todas as features para testagem\n",
        "# Há a remoção de 'items_sold' e 'items_sold_bundle' pois são tanto o target como um de seus subconjuntos\n",
        "features = [ 'stock_qty', 'dollar_quotation'\n",
        "       'shipment_type_crossdocking', 'shipment_type_próprio',\n",
        "       'product_department_Cama e Banho', 'product_department_Decoração',\n",
        "       'product_department_Gamer', 'product_department_Infantil',\n",
        "       'product_department_Keva', 'product_department_Móveis',\n",
        "       'origin_country_Importado', 'origin_country_Nacional',\n",
        "       'process_costing_no', 'process_costing_yes',\n",
        "       'flag_bundle_SKU vendido em conjunto ou sozinho',\n",
        "       'flag_bundle_SKU vendido somente sozinho', 'color_encoded',\n",
        "       'sku_encoded', 'anchor_category_encoded', 'product_category_encoded',\n",
        "       'ano', 'mes', 'dia', 'dia_da_semana', 'semana_do_ano', 'trimestre',\n",
        "       'dia_do_ano', 'eh_fim_de_semana', 'avg_website_visits_last_week',\n",
        "       'sku_height', 'sku_width', 'sku_length', 'sku_weight', 'unit_price',\n",
        "       'supplier_delivery_time']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Criando um dataframe a partir do df_final, com todas as colunas como feature\n",
        "# Pegando uma amostragem de apenas 160 mil linhas\n",
        "n = 160000\n",
        "df_parameters_sampled = df_final.drop(df_final.columns.difference(features), 1).sample(n,random_state = 42)\n",
        "\n",
        "# Separando as variáveis independentes e dependentes (X e Y)\n",
        "X2 = df_parameters_sampled\n",
        "y2 = df_final['items_sold'].sample(n,random_state = 42)\n",
        "# Dividindo o conjunto de dados em conjuntos de treinamento e teste\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=95)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalizando as features (escalando para média 0 e desvio padrão 1)\n",
        "scaler = StandardScaler()\n",
        "X2_train = scaler.fit_transform(X2_train)\n",
        "X2_test = scaler.transform(X2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from xgboost import XGBRegressor\n",
        "xgb_reg = XGBRegressor()\n",
        "scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
        "rfe = RFECV(xgb_reg, step=1, cv=5, scoring=scorer)\n",
        "rfe = rfe.fit(X2_train, y2_train)\n",
        "print(\"Feature ranking: \", rfe.ranking_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mask = rfe.get_support()\n",
        "\n",
        "# Convertendo a mascara para um array de numpy para indexação\n",
        "mask = np.array(mask)\n",
        "\n",
        "# Usando indexação booleana para pegar as features selecionadas\n",
        "best_features = [feature for i, feature in enumerate(features) if mask[i]]\n",
        "\n",
        "print(\"All features: \", X2.shape[1])\n",
        "print(features)\n",
        "\n",
        "print(\"Selected best: \", len(best_features))\n",
        "print(best_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Seleção dos melhores parâmetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Features escolhidas anteriormente para o modelo\n",
        "features = ['shipment_type_crossdocking', 'product_department_Cama e Banho', 'product_department_Gamer', 'poduct_department_Infantil', 'product_department_Móveis', 'origin_country_Importado', 'process_costing_no', 'flag_bundle_SKU vendido em conjunto ou sozinho', 'color_encoded', 'sku_encoded', 'anchor_category_encoded', 'ano', 'mes', 'dia_da_semana', 'semana_do_ano', 'dia_do_ano', 'avg_website_visits_last_week', 'sku_height', 'sku_width', 'sku_length', 'sku_weight', 'unit_price', 'supplier_delivery_time']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Criando um dataframe a partir do df_final, mas somente com as colunas das features definidas\n",
        "# Pegando uma amostragem de apenas 160 mil linhas\n",
        "n = 160000\n",
        "df_parameters_sampled = df_final.drop(df_final.columns.difference(features), 1).sample(n,random_state = 42)\n",
        "\n",
        "# Separando as variáveis independentes e dependentes (X e Y)\n",
        "X2 = df_parameters_sampled\n",
        "y2 = df_final['items_sold'].sample(n,random_state = 42)\n",
        "\n",
        "# Dividindo o conjunto de dados em conjuntos de treinamento e teste\n",
        "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=95)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Criando um dataframe a partir do df_final, agora readaptado para as features selecionadas\n",
        "df_parameters = df_final.drop(df_final.columns.difference(features), 1)\n",
        "\n",
        "# Separando as variáveis independentes e dependentes (X e Y)\n",
        "X = df_parameters\n",
        "y = df_final['items_sold']\n",
        "# Dividindo o conjunto de dados em conjuntos de treinamento e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=95)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Normalizando as features (escalando para média 0 e desvio padrão 1)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "X2_train = scaler.fit_transform(X2_train)\n",
        "X2_test = scaler.transform(X2_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Criando a grid de parâmetros a serem testados\n",
        "param_grid = {\n",
        "    'n_estimators': [10,150,200,250],\n",
        "    'max_depth': [10,15,20],\n",
        "    'learning_rate': [0.07,0.08,0.09]\n",
        "}\n",
        "\n",
        "# Definindo o modelo a ser testado\n",
        "xgb_reg = XGBRegressor()\n",
        "\n",
        "# Definindo o \"score\" para avaliarmos qual será a melhor combinação de hiperparâmetros para o modelo\n",
        "scorer = make_scorer(mean_squared_error, greater_is_better=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Realizando o grid search (remover n_jobs = -1 caso não queira usar todos os cores do computador)\n",
        "grid_search = GridSearchCV(estimator=xgb_reg, param_grid=param_grid, cv=5,scoring=scorer, refit=True)\n",
        "\n",
        "grid_search.fit(X2_train, y2_train)\n",
        "\n",
        "print(\"Melhores Hiperparâmetros: \", grid_search.best_params_)\n",
        "\n",
        "# Conseguindo os melhores estimadores\n",
        "best_xgb_model = grid_search.best_estimator_\n",
        "\n",
        "print('Best Model', best_xgb_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Aplicação do modelo com os hiperparâmetros e features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Instanciando o modelo com os hiperparâmetros definidos\n",
        "xgb_reg = XGBRegressor(n_estimators=150, max_depth=10, learning_rate=0.09)\n",
        "xgb_reg.fit(X_train, y_train)\n",
        "\n",
        "#Gerando as predições\n",
        "predictions = xgb_reg.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Métrica do Erro Quadrático Médio\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "\n",
        "#Métrica da Raiz Quadrada do Erro Médio\n",
        "RMSE = np.sqrt(mse)\n",
        "print('RMSE:', RMSE)\n",
        "\n",
        "#Métrica do Coeficiente de Determinação R² score\n",
        "r2 = r2_score(y_test, predictions)\n",
        "print(\"R2 score:\", r2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
